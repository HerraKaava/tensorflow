{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4cwNTpZX86FIcBCTWz+Gw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HerraKaava/tensorflow/blob/main/NN-Regression/Basic_modelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>The major steps in modelling with TensorFlow</h1>"
      ],
      "metadata": {
        "id": "LKF6OR79tdrD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Creating a model - define the input and output layers, as well as the hidden layers of a deep learning model.\n",
        "2. Compiling a model - define the loss function (in other words, the function which tells our model how wrong it is), the optimizer (tells our model how to improve the patterns its learning), and evaluation metrics (what we can use to interpret the performance of our model).\n",
        "3. Fitting a model - letting the model to try and find patterns between the features and the labels."
      ],
      "metadata": {
        "id": "sVaGm5xjzx6c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note. There are many definitions for a regression problem, but in our case, we're going to simplify it: predicting a continuous (output) variable based on some combination of (explanatory) variables."
      ],
      "metadata": {
        "id": "aubCSQuSvvKA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "ZBrjRwo3tnIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "gFW5kfxnwE4L"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMfTSKD9wGeP",
        "outputId": "a6b906e6-504d-4abf-f880-f3e1c3dcf18c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Creating sample regression data</h3>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BiQUtdf_to0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create features\n",
        "X = np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])\n",
        "\n",
        "# Create labels\n",
        "y = np.array([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])"
      ],
      "metadata": {
        "id": "mPSOF178v7jn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the relationship between X and y\n",
        "plt.scatter(X, y);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "tsyjQN7Rwhy_",
        "outputId": "181a1792-7694-426e-b27a-28f528bde50b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(y == X+10).all()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wr3GqHgqw7aY",
        "outputId": "7d39b67f-8466-4d56-98a3-0b126e4da4dc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "EwESwok1xoOa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Input and output shapes</h3>"
      ],
      "metadata": {
        "id": "eBTvLo8lxo2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create demo tensors for our housing price prediction problem\n",
        "house_info = tf.constant(['bedroom', 'bathroom', 'garage'])\n",
        "house_price = tf.constant([939700])\n",
        "house_info, house_price"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lzb8VrEWxrPw",
        "outputId": "89929d08-d964-474b-fbe5-7bb6cd5a48b0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,\n",
              " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert our numpy arrays into tensors with dtype float32\n",
        "X = tf.cast(tf.constant(X), dtype=tf.float32)\n",
        "y = tf.cast(tf.constant(y), dtype=tf.float32)\n",
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plAcvnbiyPJQ",
        "outputId": "4893e585-39ca-4d57-e506-5e92f3f83bd2"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gADaM4xT3Ml5",
        "outputId": "3c4ff323-bbef-4859-afd6-1b38500896c2"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTH6BAzM3QjB",
        "outputId": "ecfb6a40-91a5-40b1-eaa7-fa6a56d2f46d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([8])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.expand_dims(X, axis=1).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFb0xkY13J9D",
        "outputId": "82b7f810-4f4c-4ef2-f7ef-db3892cbea74"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([8, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.expand_dims(X, axis=-1).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-vriu3k4MIW",
        "outputId": "27b53d01-d18c-41b7-fe0c-3466d2be0e57"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([8, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "Ec1Mpw__2Edo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Creating our first NN regression model</h3>"
      ],
      "metadata": {
        "id": "K1TNoA_52Ele"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set a random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model using the Sequential API\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=['mae'])\n",
        "\n",
        "# 3. Fit the model\n",
        "model.fit(tf.expand_dims(X, axis=1), y, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVTVADJqzh8w",
        "outputId": "0b178981-883a-4cc6-ebc0-7a3c68d6c7cb"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 0s 379ms/step - loss: 10.1379 - mae: 10.1379\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 10.0054 - mae: 10.0054\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 9.8729 - mae: 9.8729\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 9.7404 - mae: 9.7404\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 9.6079 - mae: 9.6079\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c54495c7520>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* When first running the tf model, I got the following error: \"Input 0 of layer \"dense\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (None,)\"\n",
        "* This is because X has shape (8,), which corresponds to ndim=1.\n",
        "* As the error message is saying, the minimum amount of dimensions that the input vector/matrix has to have is 2 (min_ndim=2).\n",
        "* This means that if you're training your NN using only one feature, you need to reshape it to have two dimensions.\n",
        "* This can be done with: tf.expand_dims(X, axis=1).\n",
        "* The axis argument tells along which dimension the dimension expansion should be performed."
      ],
      "metadata": {
        "id": "NpiavfLv3fyF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Notice how on each epoch (an epoch in machine learning means one complete pass of the training dataset through the algorithm) the MAE (loss function) gets smaller."
      ],
      "metadata": {
        "id": "_FKjILyJ50ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Note that currently this model has no hidden layers (it only has an input layer and an output layer).\n",
        "* If no activation function is added to the output layer *tf.keras.layers.Dense(1)*, then on default, the activation function is *None*, which means that the output layer will use a linear activation function (the output will be a linear combination of the input features plus a bias term)."
      ],
      "metadata": {
        "id": "RFCQyflgP4Xj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a prediction x=17 with our model.\n",
        "# Since the relationship between X and y is that yi=Xi+10,\n",
        "# then ideally, the predicted value for y, given x=17,\n",
        "# should be 17+10=27.\n",
        "model.predict([17.0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gmv4M4UziBN",
        "outputId": "e725c7fb-09a1-42d1-cb51-d3aaa389f44a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 43ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[19.35502]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Not a good prediction, but notice that on the last training round (Epoch 5/5), the MAE is 9.6079.\n",
        "* This means that, on average, the prediction is off by 9.6079."
      ],
      "metadata": {
        "id": "ZPDTXa3cGDXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict([17.0]) + 9.6079"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGsH2TGDGNAq",
        "outputId": "a938b453-40ad-4886-87ca-25314fccd06b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 51ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[28.962921]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* This is somewhat close to 27, as it should be."
      ],
      "metadata": {
        "id": "_gmKnmohGT3V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "sXBAJKDdGghg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Improving our model</h3>"
      ],
      "metadata": {
        "id": "KifVIvY1GgpL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once again, the steps in modelling with TensorFlow:\n",
        "\n",
        "1. Construct or import a pretrained model relevant to your problem.\n",
        "\n",
        "2. Compile the model (prepare it to be used with the training data).\n",
        "  * Loss – how wrong your model's predictions are compared to the true labels (we want to minimize this).\n",
        "  * Optimizer – how your model should update its internal patterns to improve its predictions.\n",
        "  * Performance metrics – human interpretable values for how well your model is doing.\n",
        "\n",
        "3. Fit the model to the training data so it can discover patterns.\n",
        "  * Epochs – how many times the modell will go through all of the training examples.\n",
        "\n",
        "4. Evaluate the model on the test data (how reliable are our model's predictions?)."
      ],
      "metadata": {
        "id": "oujadEtTGkPj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can improve our model by altering the steps we took to create the model.\n",
        "\n",
        "1. **Creating the model** – here we might add more layers, increase the number of hidden units (neurons) within each of the hidden layers, change the activation function of each layer.\n",
        "\n",
        "2. **Compiling the model** – here we might change the optimization function or perhaps the *learning rate* of the optimization function.\n",
        "\n",
        "3. **Fitting the model** – here we might fit the model with more *epochs* (train the model with the training data with more iterations), or increase the amount of training data fed to the model."
      ],
      "metadata": {
        "id": "9KndUy4kJRSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's rebuild our model with epochs=5 --> epochs=100\n",
        "\n",
        "# 1. Create the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=['mae'])\n",
        "\n",
        "# 3. Fit the model\n",
        "model.fit(tf.expand_dims(X, axis=1), y, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdS74D9JLSEJ",
        "outputId": "121ee78c-1b2b-46bb-905a-1ad8662cab2f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 12.7327 - mae: 12.7327\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 12.6002 - mae: 12.6002\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 12.4677 - mae: 12.4677\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 12.3352 - mae: 12.3352\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 12.2027 - mae: 12.2027\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 12.0702 - mae: 12.0702\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 11.9377 - mae: 11.9377\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 11.8052 - mae: 11.8052\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 11.6727 - mae: 11.6727\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 11.5402 - mae: 11.5402\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 11.4077 - mae: 11.4077\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 11.2752 - mae: 11.2752\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 11.1427 - mae: 11.1427\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 11.0102 - mae: 11.0102\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 10.8777 - mae: 10.8777\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 10.7452 - mae: 10.7452\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 10.6127 - mae: 10.6127\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 10.4802 - mae: 10.4802\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 10.3477 - mae: 10.3477\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 10.2152 - mae: 10.2152\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 10.0827 - mae: 10.0827\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.9502 - mae: 9.9502\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.8177 - mae: 9.8177\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.6852 - mae: 9.6852\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 9.5527 - mae: 9.5527\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.4202 - mae: 9.4202\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 9.2877 - mae: 9.2877\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 9.1552 - mae: 9.1552\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 9.0227 - mae: 9.0227\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 8.8902 - mae: 8.8902\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 8.7577 - mae: 8.7577\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.6252 - mae: 8.6252\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.4927 - mae: 8.4927\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.3602 - mae: 8.3602\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.2277 - mae: 8.2277\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 8.0952 - mae: 8.0952\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 7.9627 - mae: 7.9627\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 7.8302 - mae: 7.8302\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 7.6977 - mae: 7.6977\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 7.5652 - mae: 7.5652\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 7.4327 - mae: 7.4327\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 7.3002 - mae: 7.3002\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.1850 - mae: 7.1850\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.1794 - mae: 7.1794\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.1737 - mae: 7.1737\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.1681 - mae: 7.1681\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.1625 - mae: 7.1625\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.1569 - mae: 7.1569\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.1512 - mae: 7.1512\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.1456 - mae: 7.1456\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.1400 - mae: 7.1400\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.1344 - mae: 7.1344\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.1287 - mae: 7.1287\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.1231 - mae: 7.1231\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.1175 - mae: 7.1175\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.1119 - mae: 7.1119\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.1063 - mae: 7.1063\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 7.1006 - mae: 7.1006\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.0950 - mae: 7.0950\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.0894 - mae: 7.0894\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.0838 - mae: 7.0838\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 7.0781 - mae: 7.0781\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 7.0725 - mae: 7.0725\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 7.0669 - mae: 7.0669\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.0612 - mae: 7.0612\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.0556 - mae: 7.0556\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.0500 - mae: 7.0500\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.0444 - mae: 7.0444\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.0388 - mae: 7.0388\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.0331 - mae: 7.0331\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.0275 - mae: 7.0275\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.0219 - mae: 7.0219\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.0163 - mae: 7.0163\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.0106 - mae: 7.0106\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 7.0050 - mae: 7.0050\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.9994 - mae: 6.9994\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.9938 - mae: 6.9938\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9881 - mae: 6.9881\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.9825 - mae: 6.9825\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 6.9769 - mae: 6.9769\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.9713 - mae: 6.9713\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.9656 - mae: 6.9656\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 6.9600 - mae: 6.9600\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 6.9544 - mae: 6.9544\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 6.9488 - mae: 6.9488\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 6.9431 - mae: 6.9431\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 6.9375 - mae: 6.9375\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 6.9319 - mae: 6.9319\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 6.9263 - mae: 6.9263\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 6.9206 - mae: 6.9206\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 6.9150 - mae: 6.9150\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.9094 - mae: 6.9094\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 6.9038 - mae: 6.9038\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.8981 - mae: 6.8981\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.8925 - mae: 6.8925\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 6.8869 - mae: 6.8869\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.8813 - mae: 6.8813\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 6.8756 - mae: 6.8756\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.8700 - mae: 6.8700\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.8644 - mae: 6.8644\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c5449581c00>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Notice how the loss function (mae) gets smaller with each epoch.\n",
        "* It is also worth noting that when we trained this exact same model with epochs=5, our mae was 9.6079.\n",
        "* When we increase epochs from 5 to 100, the MAE decreased from 9.6079 $\\, \\boldsymbol{\\rightarrow} \\,$ 6.8644."
      ],
      "metadata": {
        "id": "sRGj0548MYew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Again, let's make a prediction with x=17.\n",
        "# Since the relationship between X and y is yi=Xi+10,\n",
        "# then ideally, the predicted value for y, given x=17, should be 17+10=27.\n",
        "# Since on Epoch 100/100 mae=6.8644, the predicted value for y\n",
        "# is off by 6.8644, on average.\n",
        "# This means that we can expect our predicted value to be in range [27 - 6.86, 27 + 6.86].\n",
        "model.predict([17.0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYoPvJmWMcc0",
        "outputId": "5ebfbc75-dd78-4e15-808c-2b36d7dbd3c4"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 227ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[29.571836]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's change the model such that we add hidden layers with activation functions to it\n",
        "* Fully connected layers: A *Dense* layer is a fully connected layer where each neuron receives input from all neurons of the previous layer.\n",
        "* This property is useful for both hidden layers and output layers."
      ],
      "metadata": {
        "id": "YwOaXHLrQp1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "\n",
        "    # Hidden layers\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "\n",
        "    # Output layer\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=['mae'])\n",
        "\n",
        "model.fit(tf.expand_dims(X, axis=1), y, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsDrROmqQu87",
        "outputId": "90e8153c-f869-4e14-b8d5-1e6a6defff4d"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 1s/step - loss: 13.4845 - mae: 13.4845\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 13.0659 - mae: 13.0659\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 12.6613 - mae: 12.6613\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 12.2651 - mae: 12.2651\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 11.8425 - mae: 11.8425\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 11.3559 - mae: 11.3559\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 10.7842 - mae: 10.7842\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 10.0904 - mae: 10.0904\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 9.2146 - mae: 9.2146\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 8.0783 - mae: 8.0783\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 6.6345 - mae: 6.6345\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 4.8063 - mae: 4.8063\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 4.1490 - mae: 4.1490\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 3.9261 - mae: 3.9261\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 4.0521 - mae: 4.0521\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.9372 - mae: 3.9372\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 4.0066 - mae: 4.0066\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.9499 - mae: 3.9499\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.9592 - mae: 3.9592\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.9635 - mae: 3.9635\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.9109 - mae: 3.9109\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.9782 - mae: 3.9782\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.8609 - mae: 3.8609\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.9940 - mae: 3.9940\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.8096 - mae: 3.8096\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.0105 - mae: 4.0105\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.7986 - mae: 3.7986\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.9732 - mae: 3.9732\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.8160 - mae: 3.8160\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.9207 - mae: 3.9207\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.8344 - mae: 3.8344\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.8669 - mae: 3.8669\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.8537 - mae: 3.8537\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.8112 - mae: 3.8112\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.8747 - mae: 3.8747\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.7542 - mae: 3.7542\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.8967 - mae: 3.8967\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.6951 - mae: 3.6951\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.9194 - mae: 3.9194\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.7126 - mae: 3.7126\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.8509 - mae: 3.8509\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 3.7347 - mae: 3.7347\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.7925 - mae: 3.7925\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.7958 - mae: 3.7958\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.7003 - mae: 3.7003\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.8206 - mae: 3.8206\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.6397 - mae: 3.6397\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.8452 - mae: 3.8452\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.6408 - mae: 3.6408\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.7913 - mae: 3.7913\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.6669 - mae: 3.6669\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3.7259 - mae: 3.7259\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.6940 - mae: 3.6940\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.6577 - mae: 3.6577\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.7222 - mae: 3.7222\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.5869 - mae: 3.5869\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.7531 - mae: 3.7531\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.5582 - mae: 3.5582\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.6990 - mae: 3.6990\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.6217 - mae: 3.6217\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.6267 - mae: 3.6267\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.6514 - mae: 3.6514\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.5522 - mae: 3.5522\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.6836 - mae: 3.6836\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.4920 - mae: 3.4920\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.6927 - mae: 3.6927\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.5581 - mae: 3.5581\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.5840 - mae: 3.5840\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.5902 - mae: 3.5902\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.5059 - mae: 3.5059\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 3.6240 - mae: 3.6240\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.4358 - mae: 3.4358\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.6360 - mae: 3.6360\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.4687 - mae: 3.4687\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.5567 - mae: 3.5567\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.5032 - mae: 3.5032\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.4749 - mae: 3.4749\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 3.5395 - mae: 3.5395\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.3910 - mae: 3.3910\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.5768 - mae: 3.5768\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.3886 - mae: 3.3886\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.5335 - mae: 3.5335\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.4583 - mae: 3.4583\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.4024 - mae: 3.4024\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.4960 - mae: 3.4960\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.3157 - mae: 3.3157\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.5194 - mae: 3.5194\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.3524 - mae: 3.3524\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.4310 - mae: 3.4310\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.3910 - mae: 3.3910\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.3390 - mae: 3.3390\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.4316 - mae: 3.4316\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.2533 - mae: 3.2533\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.4605 - mae: 3.4605\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.3239 - mae: 3.3239\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.3300 - mae: 3.3300\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.3642 - mae: 3.3642\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.2320 - mae: 3.2320\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.4067 - mae: 3.4067\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.2258 - mae: 3.2258\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c544a167d90>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Notice when we added 3 hidden layers to the model, our loss function (mae) decrease from 6.8644 to 3.2258.\n",
        "* Crazy!!!! Cool!!!"
      ],
      "metadata": {
        "id": "eK3e_jPaSCwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Again, predict with x=17\n",
        "model.predict([17.0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hc9VaXDqSSKd",
        "outputId": "c578f511-d33a-4c22-82ab-733acd31e5a2"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 47ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[29.528141]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see if the ADAM optimizer performs better than SGD."
      ],
      "metadata": {
        "id": "e0TJs3syW1N7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "\n",
        "    # Hidden layers\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "\n",
        "    # Output layer\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "              metrics=['mae'])\n",
        "\n",
        "model.fit(tf.expand_dims(X, axis=1), y, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLvtoBhAW5x8",
        "outputId": "9a360bb6-a565-4e4a-f778-929680c61252"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 13.5443 - mae: 13.5443\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 10.9611 - mae: 10.9611\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 8.2768 - mae: 8.2768\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 4.5744 - mae: 4.5744\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.7895 - mae: 5.7895\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 7.4567 - mae: 7.4567\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 6.3418 - mae: 6.3418\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.6798 - mae: 4.6798\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.7434 - mae: 3.7434\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 4.8728 - mae: 4.8728\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 5.2528 - mae: 5.2528\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 4.8498 - mae: 4.8498\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.8100 - mae: 3.8100\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.6344 - mae: 3.6344\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.9132 - mae: 3.9132\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.9053 - mae: 3.9053\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.5705 - mae: 3.5705\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.3590 - mae: 3.3590\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.1959 - mae: 3.1959\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.2019 - mae: 3.2019\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.0737 - mae: 3.0737\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.8257 - mae: 2.8257\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.7095 - mae: 2.7095\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.5510 - mae: 2.5510\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.3416 - mae: 2.3416\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.0465 - mae: 2.0465\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.9090 - mae: 1.9090\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.5337 - mae: 1.5337\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.3855 - mae: 1.3855\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.0773 - mae: 1.0773\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.9311 - mae: 0.9311\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4876 - mae: 0.4876\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4393 - mae: 0.4393\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.5056 - mae: 1.5056\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.3697 - mae: 1.3697\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.7213 - mae: 0.7213\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.7808 - mae: 1.7808\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.9294 - mae: 0.9294\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.4142 - mae: 1.4142\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.9491 - mae: 1.9491\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.4796 - mae: 1.4796\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3410 - mae: 0.3410\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.6324 - mae: 1.6324\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.3277 - mae: 1.3277\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3761 - mae: 0.3761\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.3671 - mae: 1.3671\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.3531 - mae: 1.3531\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3584 - mae: 0.3584\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.7583 - mae: 1.7583\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.3251 - mae: 2.3251\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.4721 - mae: 1.4721\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4385 - mae: 0.4385\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.4361 - mae: 1.4361\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.4548 - mae: 1.4548\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5828 - mae: 0.5828\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.2695 - mae: 1.2695\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.8839 - mae: 1.8839\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.2823 - mae: 1.2823\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4067 - mae: 0.4067\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.9355 - mae: 0.9355\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6977 - mae: 0.6977\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5380 - mae: 0.5380\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7491 - mae: 0.7491\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2205 - mae: 0.2205\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.9707 - mae: 0.9707\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.0774 - mae: 1.0774\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5134 - mae: 0.5134\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.9221 - mae: 0.9221\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.1435 - mae: 1.1435\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6164 - mae: 0.6164\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.8325 - mae: 0.8325\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.1519 - mae: 1.1519\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.8011 - mae: 0.8011\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3438 - mae: 0.3438\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6816 - mae: 0.6816\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1879 - mae: 0.1879\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6882 - mae: 0.6882\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6584 - mae: 0.6584\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1804 - mae: 0.1804\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3353 - mae: 0.3353\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2987 - mae: 0.2987\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1267 - mae: 0.1267\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6171 - mae: 0.6171\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4565 - mae: 0.4565\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4223 - mae: 0.4223\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4898 - mae: 0.4898\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1836 - mae: 0.1836\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2366 - mae: 0.2366\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4613 - mae: 0.4613\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2485 - mae: 0.2485\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7235 - mae: 0.7235\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7809 - mae: 0.7809\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2121 - mae: 0.2121\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2732 - mae: 0.2732\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2879 - mae: 0.2879\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1421 - mae: 0.1421\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4443 - mae: 0.4443\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2587 - mae: 0.2587\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7057 - mae: 0.7057\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6246 - mae: 0.6246\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c544979ec20>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The loss function is again by far smaller (SGD vs. ADAM).\n",
        "* Notice that these MAE values are the training losses.\n",
        "* We might very well be *overfitting* to the training data when we, for example, add too many hidden layers."
      ],
      "metadata": {
        "id": "nmRBx21oYTJa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Common ways to improve a deep learning model:\n",
        "* Adding layers\n",
        "* Increase the number of hidden units\n",
        "* Change the activation functions\n",
        "* Change the optimization function\n",
        "* Change the learning rate of the optimization function\n",
        "* Fitting for longer (increasing the number of epochs)\n",
        "\n",
        "**Important** note: the *learning rate* is potentially the most important hyperparameter you can tune to improve your NN model."
      ],
      "metadata": {
        "id": "ti7kiq_ga2Fh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "aNA5HInbcpNp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Performance evaluation</h3>"
      ],
      "metadata": {
        "id": "dOiQOhibcpWa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In practice, a typical workflow you'll go through when building a NN is:\n",
        "\n",
        "* build a model $\\, \\boldsymbol{\\rightarrow} \\,$ fit it $\\, \\boldsymbol{\\rightarrow} \\,$ evaluate it $\\, \\boldsymbol{\\rightarrow} \\,$ tweak it $\\, \\boldsymbol{\\rightarrow} \\,$ fit it $\\, \\boldsymbol{\\rightarrow} \\,$ evaluate it $\\, \\boldsymbol{\\rightarrow} \\,$ tweak it $\\, \\boldsymbol{\\rightarrow} \\,$ fit it $\\, \\boldsymbol{\\rightarrow} \\,$ evaluate it ..."
      ],
      "metadata": {
        "id": "7oC-R-p1c1Ol"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When it comes to performance evaluation, there are 3 words one should memorize:\n",
        "* \"visualize, visualize, visualize\".\n",
        "\n",
        "It's a good idea to visualize:\n",
        "* the data – what kind of data are we working with? What does it look like?\n",
        "* the model itself – what does our model look like?\n",
        "* the training of a model – how does a model perform while it learns?\n",
        "* the predictions of the model – how do the predictions of a model line up against the ground truth (true labels)?"
      ],
      "metadata": {
        "id": "B9L46qb1eD1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a bigger dataset\n",
        "X = tf.range(-100, 101, 4)\n",
        "\n",
        "# Let's say that the pattern we want our model to learn is y = X + 10\n",
        "y = X + 10"
      ],
      "metadata": {
        "id": "3KKcaOaJe9o6"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VsOZlANfPzj",
        "outputId": "472c68ea-88a5-444c-dd58-729bd08f147d"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(51,), dtype=int32, numpy=\n",
              " array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
              "         -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
              "         -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
              "          32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
              "          76,   80,   84,   88,   92,   96,  100], dtype=int32)>,\n",
              " <tf.Tensor: shape=(51,), dtype=int32, numpy=\n",
              " array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
              "        -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
              "         14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
              "         66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106, 110],\n",
              "       dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data splits:**\n",
        "* Training set – the model learns from this data.\n",
        "* Validation set – the model gets validated (evaluated) and tuned on this data $\\, \\boldsymbol{\\rightarrow} \\,$ prevent overfitting to the training data.\n",
        "* Test set – the final model gets evaluated on this data $\\, \\boldsymbol{\\rightarrow} \\,$ evaluate how well does the model generalize to new, unseen data.\n",
        "\n",
        "The motivation behind data splits are that we want to ensure that our model generalizes well on new, unseen data, and to prevent overfitting to the training data."
      ],
      "metadata": {
        "id": "2j5QO2eXgDds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X.numpy(),\n",
        "                                                    y.numpy(),\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=101)\n",
        "X_train = tf.constant(X_train)\n",
        "X_test = tf.constant(X_test)\n",
        "y_train = tf.constant(y_train)\n",
        "y_test = tf.constant(y_test)"
      ],
      "metadata": {
        "id": "7ua-IWykiSJF"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Notice that we cannot pass TensorFlow tensors into sklearn's *train_test_split()* function.\n",
        "* NumPy arrays, however, can be passed into the *train_test_split()* function.\n",
        "* Use the *numpy()* function that the TensorFlow tensors have $\\, \\boldsymbol{\\rightarrow} \\,$ pass the NumPy arrays into the *train_test_split()* function $\\, \\boldsymbol{\\rightarrow} \\,$ convert the output of *the train_test_split()* function back to TensorFlow tensors."
      ],
      "metadata": {
        "id": "AZMaIXwLpiah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train), len(y_train), len(X_test), len(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ms6OTLGqrHPM",
        "outputId": "1e50ffd7-f56a-4c0c-d34a-7b44055e601b"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 40, 11, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the data\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X_train, y_train, c='b', label='training data')\n",
        "plt.scatter(X_test, y_test, c='r', label='testing data')\n",
        "plt.legend();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "NKq2X9gTrgII",
        "outputId": "11ff27d3-c444-46d6-c975-f1141aec4e01"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAq8AAAH5CAYAAACvXtfqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABJlUlEQVR4nO3de3yT9f3+8SsttFBLi0BpwRZSUAEVUXB2xVM7GVWZVutp1AN4wBM6KuCQzfNhoHiAOSc7KPjdhKlbPGwqrCBFRUBkVH5oZYItYOWgKK2itJDevz9ukzVt0qRtkjuH1/Px6KPkzt3wSRbZxYc719tmGIYhAAAAIAokWL0AAAAAIFCEVwAAAEQNwisAAACiBuEVAAAAUYPwCgAAgKhBeAUAAEDUILwCAAAganSxegHh0NTUpM8//1w9evSQzWazejkAAABowTAMffPNN+rfv78SEnzvr8ZFeP3888+Vk5Nj9TIAAADgx44dO5Sdne3z/rgIrz169JBkvhhpaWkWrwYAAAAt1dfXKycnx53bfImL8Oq6VCAtLY3wCgAAEMH8XeLJB7YAAAAQNQivAAAAiBqEVwAAAESNuLjmNRBNTU1qbGy0ehmIYF27dlViYqLVywAAIK4RXiU1NjaqurpaTU1NVi8FEa5nz57KysqiLxgAAIvEfXg1DEM7d+5UYmKicnJy2izFRfwyDEPfffed9uzZI0nq16+fxSsCACA+xX14PXTokL777jv1799fKSkpVi8HEax79+6SpD179qhv375cQgAAgAXifpvR6XRKkpKSkixeCaKB6y84Bw8etHglAADEp7gPry5cw4hA8D4BAMBahFcAAABEDcIrJEl2u11z584N+PyKigrZbDbt27cvZGvyZeHCherZs2fYf18AAGA9wmuUKigoUFlZWdAeb926dbruuusCPn/06NHauXOn0tPTg7aGUGpvOAcAAJEp7tsGgsXplN5+W9q5U+rXTzrtNMnqD6MbhiGn06kuXfz/z5yRkdGux05KSlJWVlZHlwYAANAh7LwGgcMh2e1SYaFUWmp+t9vN46EwceJErVy5UvPmzZPNZpPNZlNNTY37n/LfeOMNjRo1SsnJyXrnnXe0detWFRcXKzMzU6mpqfrRj36kZcuWeTxmy51Jm82mP//5z7rggguUkpKio446Sq+++qr7/paXDbj+KX/p0qUaNmyYUlNTddZZZ2nnzp3unzl06JB+8YtfqGfPnurdu7dmzJihCRMm6Pzzz2/z+S5cuFADBgxQSkqKLrjgAu3du9fjfn/Pr6CgQNu2bdOtt97qfr0kae/evRo/fryOOOIIpaSkaPjw4Vq8eHF7/qcAACAmOZ1SRYW0eLH5/YdypohAeO0kh0O66CLps888j9fWmsdDEWDnzZun/Px8TZo0STt37tTOnTuVk5Pjvv/222/X7NmzVVVVpeOPP17ffvutzjnnHC1fvlwbNmzQWWedpXPPPVfbt29v8/e59957dckll2jjxo0655xzdNlll+mrr77yef53332nRx55RH/5y1/01ltvafv27Zo+fbr7/oceekjPPfecFixYoFWrVqm+vl4vv/xym2tYu3atrrnmGt18882qrKxUYWGhHnjgAY9z/D0/h8Oh7Oxs3Xfffe7XS5IOHDigUaNG6bXXXtOmTZt03XXX6YorrtB7773X5poAAIhl4d6UazcjDtTV1RmSjLq6ulb3ff/998ZHH31kfP/99+1+3EOHDCM72zAk7182m2Hk5JjnBdsZZ5xhTJkyxePYihUrDEnGyy+/7Pfnjz32WOOJJ55w3x44cKDx+OOPu29LMu644w737W+//daQZLzxxhsev9fXX39tGIZhLFiwwJBkbNmyxf0zTz75pJGZmem+nZmZacyZM8d9+9ChQ8aAAQOM4uJin+scP368cc4553gcu/TSS4309PROPT9fxo0bZ0ybNs3n/Z15vwAAEOn+8Q8zv3jLNDabeX+otJXXmmPntRPefrv1jmtzhiHt2GGeF04nnXSSx+1vv/1W06dP17Bhw9SzZ0+lpqaqqqrK787r8ccf7/71YYcdprS0NPd4VG9SUlI0ePBg9+1+/fq5z6+rq9Pu3bt18sknu+9PTEzUqFGj2lxDVVWV8vLyPI7l5+cH5fk5nU7df//9Gj58uHr16qXU1FQtXbrU788BABCLnE5pyhQzv7TkOlZWZv0lBHxgqxOaXc4ZlPOC5bDDDvO4PX36dJWXl+uRRx7RkUceqe7du+uiiy5SY2Njm4/TtWtXj9s2m01NTU3tOt/w9l9AkHX0+c2ZM0fz5s3T3LlzNXz4cB122GEqKyvz+3MAAMSi9mzKFRSEbVmtEF47oV+/4J7XHklJSe7Rtv6sWrVKEydO1AUXXCDJ3KmsqakJ/qLakJ6erszMTK1bt06nn366JHPn8z//+Y9OOOEEnz83bNgwrV271uPYmjVrPG4H8vy8vV6rVq1ScXGxLr/8cklSU1OT/vvf/+qYY47pyFMEACCqReqmXEtcNtAJp50mZWdLviaG2mxSTo55XrDZ7XatXbtWNTU1+vLLL9vcET3qqKPkcDhUWVmpDz74QKWlpW2eHyq33HKLZs2apVdeeUWbN2/WlClT9PXXX7c5cvUXv/iFlixZokceeUSffPKJfve732nJkiUe5wTy/Ox2u9566y3V1tbqyy+/dP9ceXm53n33XVVVVen666/X7t27g//EAQCIAlZuyrUH4bUTEhOlefPMX7fMX67bc+eGpu91+vTpSkxM1DHHHKOMjIw2r9N87LHHdPjhh2v06NE699xzVVRUpJEjRwZ/UX7MmDFD48eP15VXXqn8/HylpqaqqKhI3bp18/kzP/7xj/WnP/1J8+bN04gRI/Tvf/9bd9xxh8c5gTy/++67TzU1NRo8eLC70/aOO+7QyJEjVVRUpIKCAmVlZfmt7QIAIFZZuSnXHjYjHBclWqy+vl7p6emqq6tTWlqax30HDhxQdXW1cnNz2wxRbXE4zAucm18nkpNjBteSkk4sPMY1NTVp2LBhuuSSS3T//fdbvZyABOP9AgBApHJVgEqeH9xyBdq//z102aatvNYc17wGQUmJVFwceRO2Is22bdv073//W2eccYYaGhr0u9/9TtXV1SotLbV6aQAAxLRAJ4GWlJgBteWmXHZ25GzKEV6DJDHR2k/eRYOEhAQtXLhQ06dPl2EYOu6447Rs2TINGzbM6qUBABCzvP0LcXa2eemjtzAa6ZtyhFeETU5OjlatWmX1MgAAiBuuywBaXiTqmgTq6zKASN6U4wNbAAAAMShahg60F+EVAAAgBkXqJNDOIrwCAADEoGgZOtBehFcAAIAYFC1DB9qL8AoAABCDomXoQHsRXgEAAKKR0ylVVEiLF5vfW3zyyspJoKFEeEWbampqZLPZVFlZGfbfu6KiQjabTfv27Qv77w0AQERzOCS7XSoslEpLze92u3m8GdfQgSOO8Pzx7OzQTssKJcJrlCooKFBZWVlQH3PixIk6//zzPY7l5ORo586dOu6444L6e4VKKF4XAAAiiqu8tWWVgKu81UuAramRVqyQFi0yv1dXR2dwlRhSEDyBzl2LMomJicrKyrJ6GQAAQPJf3mqzmeWtxcUeOSSShw60FzuvwRDg1n2wTJw4UStXrtS8efNks9lks9lUU1MjSdq0aZPOPvtspaamKjMzU1dccYW+/PJL98/+/e9/1/Dhw9W9e3f17t1bY8aM0f79+3XPPffo2Wef1SuvvOJ+zIqKilaXDbj+KX/58uU66aSTlJKSotGjR2vz5s0ea3zggQfUt29f9ejRQ9dee61uv/12nXDCCW0+r9dff11HH320unfvrsLCQvdzctm7d6/Gjx+vI444QikpKRo+fLgWL17s93VxOp265pprlJubq+7du2vIkCGa57oICACAaBKr5a3tQHjtrHZu3QfDvHnzlJ+fr0mTJmnnzp3auXOncnJytG/fPv3kJz/RiSeeqPfff19LlizR7t27dckll0iSdu7cqfHjx+vqq69WVVWVKioqVFJSIsMwNH36dF1yySU666yz3I85evRon2v49a9/rUcffVTvv/++unTpoquvvtp933PPPacHH3xQDz30kNavX68BAwboqaeeavM57dixQyUlJTr33HNVWVnpDrzNHThwQKNGjdJrr72mTZs26brrrtMVV1yh9957r83XpampSdnZ2XrxxRf10Ucf6a677tKvfvUrvfDCCx39nwAAAGvEanlrexghtHLlSuNnP/uZ0a9fP0OS8dJLL3nc39TUZNx5551GVlaW0a1bN+PMM880/vvf/3qcs3fvXqO0tNTo0aOHkZ6eblx99dXGN99806511NXVGZKMurq6Vvd9//33xkcffWR8//337X5+xqFDhpGdbRjm33Naf9lshpGTY54XZGeccYYxZcoUj2P333+/MXbsWI9jO3bsMCQZmzdvNtavX29IMmpqarw+5oQJE4zi4mKPY9XV1YYkY8OGDYZhGMaKFSsMScayZcvc57z22muGJPdrmJeXZ0yePNnjcU455RRjxIgRPp/PzJkzjWOOOcbj2IwZMwxJxtdff+3z58aNG2dMmzbNfdvb6+LN5MmTjQsvvNDveS116v0CAEBnrVjhO3c0/1qxwuqVtltbea25kO687t+/XyNGjNCTTz7p9f6HH35Yv/3tbzV//nytXbtWhx12mIqKinTgwAH3OZdddpk+/PBDlZeX61//+pfeeustXXfddaFcduAibOv+gw8+0IoVK5Samur+Gjp0qCRp69atGjFihM4880wNHz5cF198sf70pz/p66+/7tDvdfzxx7t/3e+HduM9e/ZIkjZv3qyTTz7Z4/yWt1uqqqpSXl6ex7H8/HyP206nU/fff7+GDx+uXr16KTU1VUuXLtX27dv9rvfJJ5/UqFGjlJGRodTUVP3xj38M6OcAAIgosVre2g4h/cDW2WefrbPPPtvrfYZhaO7cubrjjjtUXFwsSfq///s/ZWZm6uWXX9bPf/5zVVVVacmSJVq3bp1OOukkSdITTzyhc845R4888oj69+/v9bEbGhrU0NDgvl1fXx/kZ/aDCNu6//bbb3XuuefqoYceanVfv379lJiYqPLycr377rv697//rSeeeEK//vWvtXbtWuXm5rbr9+ratav717Yf/gNqamrq3BPwY86cOZo3b57mzp2r4cOH67DDDlNZWZkaGxvb/Lm//e1vmj59uh599FHl5+erR48emjNnjtauXRvS9QIA0G7+PgDuKm+96CIzqDb/4FY0l7e2g2XXvFZXV2vXrl0aM2aM+1h6erry8vK0evVqSdLq1avVs2dPd3CVpDFjxighIaHN4DFr1iylp6e7v3JyckLzJCycu5aUlCRnizLikSNH6sMPP5TdbteRRx7p8XXYYYdJMoPmKaeconvvvVcbNmxQUlKSXnrpJZ+P2RFDhgzRunXrPI61vN3SsGHD3NeuuqxZs8bj9qpVq1RcXKzLL79cI0aM0KBBg/Tf//7X4xxvz2HVqlUaPXq0brrpJp144ok68sgjtXXr1vY+LQAAQivQD4DHYnlrO1gWXnft2iVJyszM9DiemZnpvm/Xrl3q27evx/1dunRRr1693Od4M3PmTNXV1bm/duzYEeTV/8DCrXu73a61a9eqpqZGX375pZqamjR58mR99dVXGj9+vNatW6etW7dq6dKluuqqq+R0OrV27Vr95je/0fvvv6/t27fL4XDoiy++0LBhw9yPuXHjRm3evFlffvmlDh482KG13XLLLXr66af17LPP6pNPPtEDDzygjRs3undovbnhhhv0ySef6LbbbtPmzZu1aNEiLVy40OOco446yr1zXFVVpeuvv167d+/2+7ocddRRev/997V06VL997//1Z133uk3TAMAEFbt/QB4rJW3tkNMtg0kJycrLS3N4yskLJy7Nn36dCUmJuqYY45RRkaGtm/frv79+2vVqlVyOp0aO3ashg8frrKyMvXs2VMJCQlKS0vTW2+9pXPOOUdHH3207rjjDj366KPuSzsmTZqkIUOG6KSTTlJGRoZWrVrVobVddtllmjlzpqZPn66RI0equrpaEydOVLdu3Xz+zIABA/SPf/xDL7/8skaMGKH58+frN7/5jcc5d9xxh0aOHKmioiIVFBQoKyur1VAFb6/L9ddfr5KSEl166aXKy8vT3r17ddNNN3XouQEAEHT+ulsls7u15b+Ouspbx483v8fwpQLN2QzD2ysVgt/IZtNLL73kDhuffvqpBg8erA0bNnj0f55xxhk64YQTNG/ePD3zzDOaNm2ax4eKDh06pG7duunFF1/UBRdcENDvXV9fr/T0dNXV1bUKsgcOHFB1dbVyc3PbDFdtcjjMN13zvy3l5JjBNQ7+BhSIn/70p8rKytJf/vIXq5fSKUF5vwAA0FxFhXmJgD8rVsTOpAEv2sprzVk2YSs3N1dZWVlavny5O7zW19dr7dq1uvHGGyWZnzbft2+f1q9fr1GjRkmS3nzzTTU1NbX6ZLqlSkrMSRYxOGGrI7777jvNnz9fRUVFSkxM1OLFi7Vs2TKVl5dbvTQAACJPhH0APNKFNLx+++232rJli/t2dXW1Kisr1atXLw0YMEBlZWV64IEHdNRRRyk3N1d33nmn+vfv796dHTZsmM466yxNmjRJ8+fP18GDB3XzzTfr5z//uc+mAcvE0ty1TrLZbHr99df14IMP6sCBAxoyZIj+8Y9/eHw4DwAA/MDCD4BHo5CG1/fff1+FzbbBp06dKkmaMGGCFi5cqF/+8pfav3+/rrvuOu3bt0+nnnqqlixZ4vHPsc8995xuvvlmnXnmmUpISNCFF16o3/72t6FcNjqpe/fuWrZsmdXLAAAgOrg+AF5b6/26V5vNvD+Gu1vbI2zXvFop5Ne8Im7wfgEAhISrbUDy3t0aBxVYgV7zGpNtAwAAAJHA6TQ/j7V4sfndZ516nHe3todlH9iKNHGwAY0gCPUUMQBA7PBWRpSdbbZses2ifAA8IHEfXrt27SqbzaYvvvhCGRkZbRbpI34ZhqHGxkZ98cUXSkhIUFJSktVLAgBEMNdVAC33xlwzB3xupvIBcL/i/ppXyWxF+Oyzz9h9hV8pKSnq168f4RUA4JPTaU51bTksy8X1+avqajZVm4v4ntdIkpqaqqOOOqrD41ARHxITE9WlSxd25wEAbXr7bd/BVTJ3Y3fsMM9jk7X9CK8/SExMVCJ//QEAAJ3EzIHQom0AAAAgiJg5EFqEVwAAgCByzRzwdZWZzSbl5DBzoKMIrwAAAO3gr7s1MdGsw5JaB1jX7blz+bBWRxFeAQAAAuRwmE0ChYVSaan53W43jzfHzIHQoSoLAAAgAL66W9ua4Op0MnMgUIHmNcIrAACAH3S3hl6geY3LBgAAAPxoT3crQovwCgAA4AfdrZGD8AoAAOAH3a2Rg/AKAADgB92tkYPwCgAA4AfdrZGD8AoAAOKev8EDEt2tkaKL1QsAAACwksMhTZni2SaQnW3utLYMpCUlUnEx3a1WoucVAADErY4MHkBo0PMKAADQBqfT3HH1to3nOlZW5v0SAliH8AoAAOISgweiE+EVAADEJQYPRCfCKwAAiEsMHohOhFcAABCXGDwQnQivAAAgNvkpb2XwQHQivAIAgNjjcEh2u1RYKJWWmt/tdvN4MwweiD70vAIAgNjSgfJWp5PBA1YLNK8RXgEAQOxwOs0dVl8dWDabua1aXU06jTAMKQAAAPGH8taYR3gFAACxg/LWmEd4BQAAsYPy1phHeAUAALGD8taYR3gFAABRwU9tq4ny1phHeAUAABEvwNpWE+WtMY2qLAAAENE6UNtqorw1qtDz2gzhFQCA6ERta/yg5xUAAEQ9alvREuEVAABELGpb0RLhFQAARCxqW9ES4RUAAEQsalvRkuXh1W63y2aztfqaPHmyJKmgoKDVfTfccIPFqwYAAOFAbSta6mL1AtatWydns5bhTZs26ac//akuvvhi97FJkybpvvvuc99OSUkJ6xoBAEBoBNJm5aptnTLF88Nb2dlmcKW2Nb5YHl4zMjI8bs+ePVuDBw/WGWec4T6WkpKirKyscC8NAACEkMPhPZDOm9c6kJaUSMXF1LYiAi4baK6xsVF//etfdfXVV8vW7N8GnnvuOfXp00fHHXecZs6cqe+++67Nx2loaFB9fb3HFwAAiByuwQMta7Bqa83j3iZnJSZKBQXS+PHmd4JrfLJ857W5l19+Wfv27dPEiRPdx0pLSzVw4ED1799fGzdu1IwZM7R582Y5vM6DM82aNUv33ntvGFYMAADay+k0d1y9jUkyDPNa1rIyc6eVgIqWImrCVlFRkZKSkvTPf/7T5zlvvvmmzjzzTG3ZskWDBw/2ek5DQ4MaGhrct+vr65WTk8OELQAAIkBFhVRY6P+8FSvMHVbEh0AnbEXMzuu2bdu0bNmyNndUJSkvL0+S2gyvycnJSk5ODvoaAQBA5zF4AJ0RMde8LliwQH379tW4cePaPK+yslKS1I82YgAAohKDB9AZEbHz2tTUpAULFmjChAnq0uV/S9q6dasWLVqkc845R71799bGjRt166236vTTT9fxxx9v4YoBAEBHuQYP1NZ6v+7VZjPvZ/AAvImInddly5Zp+/btuvrqqz2OJyUladmyZRo7dqyGDh2qadOm6cILL2zzmlgAAGAtp9O8rnXxYvN7szp3SQweQOdE1Ae2QiXQC4ABAEDntKe71du5OTkMHohXgeY1wisAAAgKV3dry2Th2k39+99bh9JAJmwhPhBemyG8AgAQWk6nZLe3Hjrg4rqOtbqacArvAs1rEXHNKwAAiG5vv+07uErmbuyOHeZ5QGcQXgEAQKfR3YpwIbwCAIBOo7sV4UJ4BQAAnebqbm1ZfeVis5lNAnS3orMIrwAAoNPobkW4EF4BAIBf/gYPSGYN1t//Lh1xhOfx7GzvNVlAR0TEeFgAABC52jN4oKREKi6muxWhQ88rAADwqSODB4COoOcVAAB0itNp7rh62+ZyHSsr834JARAqhFcAAOAVgwcQiQivAADAKwYPIBIRXgEAgFcMHkAkIrwCAACvGDyASER4BQAgDgXS28rgAUQiwisAAHHG4ZDsdqmwUCotNb/b7ebxlhg8gEhDzysAAHGko72tTieDBxBageY1wisAAHHC6TR3WH3VX9ls5o5qdTXBFOHHkAIAAOCB3lbEAsIrAABxgt5WxALCKwAAcYLeVsQCwisAAHGC3lbEAsIrAACxwk95K72tiAWEVwAAYkGA5a30tiLaUZUFAEC060B5K72tiDT0vDZDeAUAxCzKWxEj6HkFACAeUN6KOEN4BQAgmlHeijhDeAUAIJpR3oo4Q3gFACCaUd6KOEN4BQAgmlHeijhDeAUAIIL5mTtgorwVcaSL1QsAAADeORzSlCmeZQLZ2eZGa6s8WlIiFRdT3oqYR88rAAARqANzB4CoRs8rAABRyuk0d1y9bS+5jpWV+biEAIhxhFcAACIMcwcA3wivAABEGOYOAL4RXgEAiDDMHQB8I7wCABBhmDsA+EZ4BQAgjALpbWXuAOCb5eH1nnvukc1m8/gaOnSo+/4DBw5o8uTJ6t27t1JTU3XhhRdq9+7dFq4YAICOcTgku10qLJRKS83vdrt5vCXmDgDeRcSQgmOPPVbLli1z3+7S5X/LuvXWW/Xaa6/pxRdfVHp6um6++WaVlJRo1apVViwVAIAO8dXbWltrHvcWSJk7ALQWEeG1S5cuysrKanW8rq5OTz/9tBYtWqSf/OQnkqQFCxZo2LBhWrNmjX784x+He6kAALSbv95Wm83sbS0ubh1MExOlgoJwrBKIDpZfNiBJn3zyifr3769Bgwbpsssu0/bt2yVJ69ev18GDBzVmzBj3uUOHDtWAAQO0evVqn4/X0NCg+vp6jy8AAKxCbysQPJaH17y8PC1cuFBLlizRU089perqap122mn65ptvtGvXLiUlJalnz54eP5OZmaldu3b5fMxZs2YpPT3d/ZWTkxPiZwEAgG/0tgLBY/llA2effbb718cff7zy8vI0cOBAvfDCC+revXuHHnPmzJmaOnWq+3Z9fT0BFgBgGXpbgeCxfOe1pZ49e+roo4/Wli1blJWVpcbGRu3bt8/jnN27d3u9RtYlOTlZaWlpHl8AAFiF3lYgeCIuvH777bfaunWr+vXrp1GjRqlr165avny5+/7Nmzdr+/btys/Pt3CVAAAEjt5WIHgsD6/Tp0/XypUrVVNTo3fffVcXXHCBEhMTNX78eKWnp+uaa67R1KlTtWLFCq1fv15XXXWV8vPzaRoAAESMQAYP0NsKBIfl17x+9tlnGj9+vPbu3auMjAydeuqpWrNmjTIyMiRJjz/+uBISEnThhReqoaFBRUVF+v3vf2/xqgEAMDkcZg1W8zaB7Gxzp5XeViD4bIbhrXUuttTX1ys9PV11dXVc/woACBpfgwdclwKwowoELtC8ZvllAwAARCN/gwckc/CAt0sIAHQc4RUAgA5g8ABgDcIrAAAdwOABwBqEVwAAOoDBA4A1CK8AAHQAgwcAaxBeAQDwwl93K4MHAGsQXgEAaMHhkOx2qbBQKi01v9vt5vHmGDwAhB89rwAANNOR7lank8EDQGcFmtcIrwAA/MDpNHdYfVVg2Wzmrmp1NeEUCDaGFAAA0E50twKRj/AKAMAP6G4FIh/hFQCAH9DdCkQ+wisAAD+guxWIfIRXAED88FPeSncrEPkIrwCA+BBgeSvdrUBkoyoLABD7OlDeSncrEF70vDZDeAWAOEZ5KxAV6HkFAECivBWIMYRXAEBso7wViCmEVwBAbKO8FYgphFcAQGyjvBWIKYRXAEBso7wViCmEVwBA1PIzc+B/KG8FYkYXqxcAAEBHOBzSlCmeRQLZ2eYmq9csWlIiFRdT3gpEOXpeAQBRpwMzBwBEOHpeAQAxyek0d1y9bb24jpWVtXEJAYCoRngFAEQVZg4A8Y3wCgCIKswcAOIb4RUAEFWYOQDEN8IrACCqMHMAiG+EVwBARPHX3crMASC+EV4BABHD4ZDsdqmwUCotNb/b7ebx5pg5AMQvel4BABGhI92tTiczB4BYEWheI7wCACzndJo7rL4qsGw2c1e1uppwCsQqhhQAAKIG3a0AAkV4BQBYju5WAIEivAIALEd3K4BAEV4BAJajuxVAoAivAADL0d0KIFCEVwBAyPkbPCDR3QogMF2sXgAAILY5HNKUKZ5tAtnZ5k5ry0BaUiIVF9PdCsA3el4BACHTkcEDAOJT1PS8zpo1Sz/60Y/Uo0cP9e3bV+eff742b97scU5BQYFsNpvH1w033GDRigEAgXA6zR1Xb1skrmNlZd4vIQAAXywPrytXrtTkyZO1Zs0alZeX6+DBgxo7dqz279/vcd6kSZO0c+dO99fDDz9s0YoBAIFg8ACAULD8mtclS5Z43F64cKH69u2r9evX6/TTT3cfT0lJUVZWVriXBwDoIAYPAAgFy3deW6qrq5Mk9erVy+P4c889pz59+ui4447TzJkz9d133/l8jIaGBtXX13t8AQDCi8EDAELB8p3X5pqamlRWVqZTTjlFxx13nPt4aWmpBg4cqP79+2vjxo2aMWOGNm/eLIfD4fVxZs2apXvvvTdcywYAeOEaPFBb6/26V5vNvJ/BAwDaI6LaBm688Ua98cYbeuedd5Sdne3zvDfffFNnnnmmtmzZosGDB7e6v6GhQQ0NDe7b9fX1ysnJoW0AAILI6fRfaeVqG5A8AyxtAwBaipq2AZebb75Z//rXv7RixYo2g6sk5eXlSZK2bNni9f7k5GSlpaV5fAEAgsfhkOx2qbBQKi01v9vt5vHmGDwAINgsv2zAMAzdcssteumll1RRUaHc3Fy/P1NZWSlJ6seFUgAQdr66W2trzeMtQymDBwAEk+WXDdx0001atGiRXnnlFQ0ZMsR9PD09Xd27d9fWrVu1aNEinXPOOerdu7c2btyoW2+9VdnZ2Vq5cmVAvwdDCgAgOJxOc4fVVwWW6zrW6mrCKYD2CTSvWR5eba4Ln1pYsGCBJk6cqB07dujyyy/Xpk2btH//fuXk5OiCCy7QHXfcEXAQJbwCQHBUVJiXCPizYoVUUBDq1QCIJYHmtYi4bKAtOTk5Ae+wAgBCi+5WAFaLmA9sAQAiH92tAKxGeAUABMzV3erjii/ZbFJODt2tAEKH8AoAkGR+GKuiQlq82PzudLY+JzFRmjfP/HXLAOu6PXcuH9YCEDqEVwBAwL2tEt2tAKxledtAONA2AAC++ept9TcFK5AJWwAQqKipygoHwisAeEdvK4BIEXXjYQEA4ff2276Dq2Tuxu7YYZ4HAJGA8AoAcYzeVgDRhvAKAHGM3lYA0YbwCgBxjN5WANGG8AoAcYzeVgDRhvAKALEsgMkD9LYCiCZdrF4AACBEHA5pyhTPOoHsbHOrtUUiLSmRiovpbQUQ+eh5BYBY1NHJAwBgEXpeASBeOZ3mjqu3vQnXsbIyr5cQAECkI7wCQKxh8gCAGEZ4BYBYw+QBADGM8AoAsYbJAwBiGOEVAGINkwcAxDDCKwBEGb/VrUweABDDCK8AEEUcDslulwoLpdJS87vdbh73wOQBADGKnlcAiBIdqm51Opk8ACAqBJrXCK8AEAWcTnOH1VcDls1mbqpWV5NNAUQnhhQAQAyhuhUATIRXAIgCVLcCgInwCgBRgOpWADARXgEgClDdCgAmwisARAGqWwHARHgFAIv5HTrwA6pbAUDqYvUCACCeORzSlCmeTQLZ2eYuq7cwWlIiFRdT3QogftHzCgAW6dDQAQCIUfS8AkAEczrNHVdv2weuY2Vlvi8hAIB4RXgFAAswdAAAOobwCgAWYOgAAHQM4RUALMDQAQDoGMIrAFiAoQMA0DGEVwAIAX/drQwdAICOIbwCQJA5HJLdLhUWSqWl5ne73TzeHEMHAKD96HkFgCDqSHer08nQAQAINK8RXgEgSJxOc4fVVwWWzWbuqlZXE04BoCWGFABAmNHdCgChR3gFgCChuxUAQi9qwuuTTz4pu92ubt26KS8vT++9957VSwIAD3S3AkDoRUV4ff755zV16lTdfffd+s9//qMRI0aoqKhIe/bssXppAOBGdysAhF5UhNfHHntMkyZN0lVXXaVjjjlG8+fPV0pKip555hmv5zc0NKi+vt7jCwA6zU95K92tABB6ER9eGxsbtX79eo0ZM8Z9LCEhQWPGjNHq1au9/sysWbOUnp7u/srJyQnXcgHEqgDLW+luBYDQivjw+uWXX8rpdCozM9PjeGZmpnbt2uX1Z2bOnKm6ujr3144dO8KxVACxylXe2rJKoLbWPO4lwNbUSCtWSIsWmd+rqwmuABAMXaxeQCgkJycrOTnZ6mUAiAVOpzRlSuupA5J5zGaTysqk4mKP6wESE6WCgrCtEgDiRsTvvPbp00eJiYnavXu3x/Hdu3crKyvLolUBiBuUtwJARIn48JqUlKRRo0Zp+fLl7mNNTU1avny58vPzLVwZgLhAeSsARJSouGxg6tSpmjBhgk466SSdfPLJmjt3rvbv36+rrrrK6qUBiHWUtwJARImK8HrppZfqiy++0F133aVdu3bphBNO0JIlS1p9iAsAgs5V3lpb6/26V5vNvJ/yVgAIC5thePvTOLbU19crPT1ddXV1SktLs3o5AKKNq21A8gywrvJWOrAAoNMCzWsRf80rAISUn8EDkihvBYAIEhWXDQBASDgcZg1W8zaB7GxzTFbLQFpSYtZhvf22+eGsfv3MSwUYlwUAYcVlAwDik+tSgJZ/BHIpAABYgssGAMAXf4MHJHPwgLdLCAAAliK8Aog/DB4AgKhFeAUQfxg8AABRi/AKIP4weAAAohbhFUD8cQ0ecH04qyWbTcrJYfAAAEQgwiuAmBJIbasSE806LKl1gHXdnjuXGiwAiECEVwAxw+GQ7HapsFAqLTW/2+3m8VYYPAAAUYmeVwAxocO1rU4ngwcAIAIEmtcIrwCintNp7rD6ar+y2cwN1epqcikARCqGFACIG9S2AkD8ILwCiHrUtgJA/CC8Aoh61LYCQPwgvAKIetS2AkD8ILwCiHrUtgJA/CC8Aoh4gQweoLYVAOJDF6sXAABtcTikKVM82wSys82d1paBtKREKi6mthUAYhk9rwAiVocHDwAAog49rwCimtNp7rh6++u161hZmfdLCAAAsYvwCiAiMXgAAOAN4RVARGLwAADAG8IrgIjE4AEAgDeEVwARicEDAABvCK8ALOGvu5XBAwAAbwivAMLO4ZDsdqmwUCotNb/b7ebx5hg8AABoiZ5XAGHVke5Wp5PBAwAQ6wLNa4RXAGHjdJo7rL4qsGw2c1e1uppwCgDxhiEFACIO3a0AgM4ivAIIG7pbAQCdRXgFEDZ0twIAOovwCiBs6G4FAHQW4RVA0NDdCgAINcIrgKCguxUAEA5UZQHoNLpbAQCdRc9rM4RXIHTobgUABAM9rwDCgu5WAEA4EV4BdArdrQCAcCK8AugUulsBAOFEeAXQKXS3AgDCybLwWlNTo2uuuUa5ubnq3r27Bg8erLvvvluNjY0e59hstlZfa9assWrZAFqguxUAEE5drPqNP/74YzU1NekPf/iDjjzySG3atEmTJk3S/v379cgjj3icu2zZMh177LHu27179w73coH4FGCflau7dcoUzw9vZWebwZXuVgBAsERUVdacOXP01FNP6dNPP5Vk7rzm5uZqw4YNOuGEEzr8uFRlAR3gcHhPo/Pm+UyjdLcCADoq0Lxm2c6rN3V1derVq1er4+edd54OHDigo48+Wr/85S913nnntfk4DQ0NamhocN+ur68P+lqBmOZr6kBtrXncxyisxESpoCA8SwQAxKeI+cDWli1b9MQTT+j66693H0tNTdWjjz6qF198Ua+99ppOPfVUnX/++Xr11VfbfKxZs2YpPT3d/ZWTkxPq5QOxw+k0d1y9/aOM61hZmXkeAABhFvTLBm6//XY99NBDbZ5TVVWloUOHum/X1tbqjDPOUEFBgf785z+3+bNXXnmlqqur9XYbjefedl5zcnK4bAAIREWFVFjo/7wVK9hmBQAEjWWXDUybNk0TJ05s85xBgwa5f/3555+rsLBQo0eP1h//+Ee/j5+Xl6fy8vI2z0lOTlZycnJA6wXQAlMHAAARLOjhNSMjQxkZGQGdW1tbq8LCQo0aNUoLFixQQoL/qxgqKyvVj7ZzIHSYOgAAiGCWfWCrtrZWBQUFGjhwoB555BF98cUX7vuysrIkSc8++6ySkpJ04oknSpIcDoeeeeYZv5cWAOgE19SB2lrv173abOb9TB0AAFjAsvBaXl6uLVu2aMuWLcrOzva4r/lluPfff7+2bdumLl26aOjQoXr++ed10UUXhXu5QMzwW2flmjpw0UVmUG0eYJk6AACwWET1vIYKPa+AqV3Vrd5Ozslh6gAAICQCzWuEVyBO+KpudW2meq1uZeoAACBMCK/NEF4R75xOyW733ERtznUZa3U12RQAYI1A81rEDCkAEDpvv+07uErmbuyOHeZ5AABEMsIrEAeobgUAxArCKxAHqG4FAMQKwisQB1zVra4PZ7Vks5lFAlS3AgAiHeEViAOu6lapdYCluhUAEE0Ir0AscDqligpp8WLzu9PZ6pSSErMO64gjPI9nZ/uoyQIAIAJZNmELQJC0Y/JASYlUXEx1KwAgetHzCkSzDk0eAAAg8tDzCsQ6p9PccfX290/XsbIyr5cQAAAQrQivQLRi8gAAIA4RXoFoxeQBAEAcIrwC0YrJAwCAOER4BaIVkwcAAHGI8ApEoABqW5k8AACIS4RXIMI4HJLdLhUWSqWl5ne73TzeCpMHAABxhp5XIIJ0uLbV6WTyAAAgqgWa1wivQIRwOs0dVl/tVzabuaFaXU0uBQDEHoYUAFGG2lYAAPwjvAIRgtpWAAD8I7wCEYLaVgAA/CO8AhGC2lYAAPwjvAJh4q+7ldpWAAD8I7wCYRBodyu1rQAAtI2qLCDEOtLdSm0rACDe0PPaDOEVVqG7FQCAwNDzCkQAulsBAAguwisQQnS3AgAQXIRXIITobgUAILgIr0AI0d0KAEBwEV6BEKK7FQCA4CK8Ap3gb/CARHcrAADB1MXqBQDRyuGQpkzxbBPIzjZ3WlsG0pISqbiY7lYAADqLnlegAzoyeAAAAPhGzysQIk6nuePq7a99rmNlZd4vIQAAAJ1DeAXaicEDAABYh/AKtBODBwAAsA7hFWgnBg8AAGAdwivQTgweAADAOoRXoAV/3a0MHgAAwDqWhle73S6bzebxNXv2bI9zNm7cqNNOO03dunVTTk6OHn74YYtWi3jgcEh2u1RYKJWWmt/tdvN4cwweAADAGpYPKbjvvvs0adIk9+0ePXq4f11fX6+xY8dqzJgxmj9/vv7f//t/uvrqq9WzZ09dd911ViwXMcxXd2ttrXm8ZShl8AAAAOFneXjt0aOHsrKyvN733HPPqbGxUc8884ySkpJ07LHHqrKyUo899hjhFUHlr7vVZjO7W4uLPcNpYqJUUBCuVQIAAMuveZ09e7Z69+6tE088UXPmzNGhQ4fc961evVqnn366kpKS3MeKioq0efNmff311z4fs6GhQfX19R5fQFvobgUAIDpYuvP6i1/8QiNHjlSvXr307rvvaubMmdq5c6cee+wxSdKuXbuUm5vr8TOZmZnu+w4//HCvjztr1izde++9oV08YgrdrQAARIeg77zefvvtrT6E1fLr448/liRNnTpVBQUFOv7443XDDTfo0Ucf1RNPPKGGhoZOrWHmzJmqq6tzf+3YsSMYTw0xjO5WAACiQ9B3XqdNm6aJEye2ec6gQYO8Hs/Ly9OhQ4dUU1OjIUOGKCsrS7t37/Y4x3Xb13WykpScnKzk5OT2LRxxzdXdWlvr/bpXm828n+5WAACsFfTwmpGRoYyMjA79bGVlpRISEtS3b19JUn5+vn7961/r4MGD6tq1qySpvLxcQ4YM8XnJANARru7Wiy4yg2rzAEt3KwAAkcOyD2ytXr1ac+fO1QcffKBPP/1Uzz33nG699VZdfvnl7mBaWlqqpKQkXXPNNfrwww/1/PPPa968eZo6dapVy0YU8jd0wIXuVgAAIp/NMLz9I2no/ec//9FNN92kjz/+WA0NDcrNzdUVV1yhqVOnevyT/8aNGzV58mStW7dOffr00S233KIZM2a06/eqr69Xenq66urqlJaWFuynggjmcJgVWM2bBLKzzV1WX2HU6aS7FQCAcAs0r1kWXsOJ8BqffA0dcF0GwG4qAACRI9C8ZnnPKxAK/oYOSObQAV+XEAAAgMhEeEVMYugAAACxifCKmMTQAQAAYhPhFTGJoQMAAMQmwitikmvogOvDWS3ZbFJODkMHAACINoRXRCV/3a2uoQNS6wDL0AEAAKIX4RVRx+GQ7HapsFAqLTW/2+3m8eYYOgAAQOyh5xVRpSPdrQwdAAAg8jGkoBnCa2xwOs0dVl8VWDabuataXU04BQAg2jCkADGH7lYAAEB4RdSguxUAABBeETXobgUAAIRXRA26WwEAAOEVEYPuVgAA4A/hFRGB7lYAABAIqrJgObpbAQAAPa/NEF4jF92tAABAoucVUYLuVgAA0B6EV1iK7lYAANAehFdYiu5WAADQHoRXWIruVgAA0B6EV1iK7lYAANAehFeElL/BAxLdrQAAIHBdrF4AYpfDIU2Z4tkmkJ1t7rS2DKQlJVJxMd2tAACgbfS8IiQ6MngAAADEL3peYRmn09xx9fbXItexsjLvlxAAAAC0hfCKoGPwAAAACBXCK4KOwQMAACBUCK8IOgYPAACAUCG8IugYPAAAAEKF8Ip2CaS3lcEDAAAgVAivCJjDIdntUmGhVFpqfrfbzeMtMXgAAACEAj2vCEhHe1udTgYPAAAA/wLNa4RX+OV0mjusvuqvbDZzR7W6mmAKAAA6hiEFCBp6WwEAQKQgvMIvelsBAECkILzCL3pbAQBApCC8wi96WwEAQKQgvMIvelsBAECkILwioMED9LYCAIBI0MXqBcBaDoc0ZYpnm0B2trnT2jKQlpRIxcX0tgIAAOvQ8xrHOjp4AAAAINgivue1oqJCNpvN69e6deskSTU1NV7vX7NmjVXLjhlOp7nj6u2vLq5jZWXeLyEAAACwimWXDYwePVo7WxSD3nnnnVq+fLlOOukkj+PLli3Tscce677du3fvsKwxlrVn8EBBQdiWBQAA0CbLwmtSUpKysrLctw8ePKhXXnlFt9xyi2wtPtLeu3dvj3PReQweAAAA0Shi2gZeffVV7d27V1dddVWr+8477zz17dtXp556ql599VW/j9XQ0KD6+nqPL3hi8AAAAIhGERNen376aRUVFSk7O9t9LDU1VY8++qhefPFFvfbaazr11FN1/vnn+w2ws2bNUnp6uvsrJycn1MuPOgweAAAA0SjobQO33367HnrooTbPqaqq0tChQ923P/vsMw0cOFAvvPCCLrzwwjZ/9sorr1R1dbXefvttn+c0NDSooaHBfbu+vl45OTlx1TbgdPqvtHK1DUieH9yibQAAAIRboG0DQb/mddq0aZo4cWKb5wwaNMjj9oIFC9S7d2+dd955fh8/Ly9P5eXlbZ6TnJys5ORkv48VqwLtbnUNHvB27ty5BFcAABB5gh5eMzIylJGREfD5hmFowYIFuvLKK9W1a1e/51dWVqofF2L65Ku7tbbWPN5yN5XBAwAAIJpYPmHrzTffVHV1ta699tpW9z377LNKSkrSiSeeKElyOBx65pln9Oc//zncy4wK/rpbbTazu7W42DOcJiZShwUAAKKD5eH16aef1ujRoz2ugW3u/vvv17Zt29SlSxcNHTpUzz//vC5yXagJD3S3AgCAWGd5eF20aJHP+yZMmKAJEyaEcTXRje5WAAAQ6yKmKgudR3crAACIdYTXGEJ3KwAAiHWE1yjhdEoVFdLixeZ3p7P1OYmJZh2W1DrAum7PnUuTAAAAiF6E1yjgcEh2u1RYKJWWmt/tdvN4S67u1iOO8Dyenc3QAQAAEP2CPmErEgU6sSES+ept9TcFK5AJWwAAAJEi0LxGeI1gTqe5w+qr/spmM3dUq6sJpgAAILoFmte4bCCCtae3FQAAIB4QXiMYva0AAACeCK8RjN5WAAAAT4TXCEZvKwAAgCfCawSjtxUAAMAT4dVKAUweoLcVAADgf7pYvYC45XBIU6Z41glkZ5tbrS0SaUmJVFxMbysAAAA9r1bo6OQBAACAGEXPa6RyOs0dV29/Z3AdKyvzegkBAABAvCO8hhuTBwAAADqM8BpuTB4AAADoMMJruDF5AAAAoMMIr+HG5AEAAIAOI7wGmd/qViYPAAAAdBjhNYgcDslulwoLpdJS87vdbh73wOQBAACADqHnNUg6VN3qdDJ5AAAAQIHnNcJrEDid5g6rrwYsm83cVK2uJpsCAAB4w5CCMKK6FQAAIDwIr0FAdSsAAEB4EF6DgOpWAACA8CC8BgHVrQAAAOFBeA0CqlsBAADCg/AaJFS3AgAAhF4XqxcQS0pKpOJiqlsBAABChfAaZImJUkGB1asAAACITVw2AAAAgKhBeAUAAEDUILwCAAAgahBeAQAAEDUIrwAAAIgahFcAAABEDcIrAAAAogbhFQAAAFGD8AoAAICoQXgFAABA1CC8AgAAIGqELLw++OCDGj16tFJSUtSzZ0+v52zfvl3jxo1TSkqK+vbtq9tuu02HDh3yOKeiokIjR45UcnKyjjzySC1cuDBUSwYAAECEC1l4bWxs1MUXX6wbb7zR6/1Op1Pjxo1TY2Oj3n33XT377LNauHCh7rrrLvc51dXVGjdunAoLC1VZWamysjJde+21Wrp0aaiWDQAAgAhmMwzDCOVvsHDhQpWVlWnfvn0ex9944w397Gc/0+eff67MzExJ0vz58zVjxgx98cUXSkpK0owZM/Taa69p06ZN7p/7+c9/rn379mnJkiU+f8+GhgY1NDS4b9fV1WnAgAHasWOH0tLSgvsEAQAA0Gn19fXKycnRvn37lJ6e7vO8LmFck4fVq1dr+PDh7uAqSUVFRbrxxhv14Ycf6sQTT9Tq1as1ZswYj58rKipSWVlZm489a9Ys3Xvvva2O5+TkBGXtAAAACI1vvvkmMsPrrl27PIKrJPftXbt2tXlOfX29vv/+e3Xv3t3rY8+cOVNTp051325qatJXX32l3r17y2azBfNpeOX6mwM7vZ54XXzjtfGO18U3XhvveF1847XxjtfFt3C/NoZh6JtvvlH//v3bPK9d4fX222/XQw891OY5VVVVGjp0aHseNuiSk5OVnJzscczXh8ZCKS0tjf8QvOB18Y3XxjteF994bbzjdfGN18Y7XhffwvnatLXj6tKu8Dpt2jRNnDixzXMGDRoU0GNlZWXpvffe8zi2e/du932u765jzc9JS0vzuesKAACA2NWu8JqRkaGMjIyg/Mb5+fl68MEHtWfPHvXt21eSVF5errS0NB1zzDHuc15//XWPnysvL1d+fn5Q1gAAAIDoErKqrO3bt6uyslLbt2+X0+lUZWWlKisr9e2330qSxo4dq2OOOUZXXHGFPvjgAy1dulR33HGHJk+e7P4n/xtuuEGffvqpfvnLX+rjjz/W73//e73wwgu69dZbQ7XsoEhOTtbdd9/d6tKFeMfr4huvjXe8Lr7x2njH6+Ibr413vC6+ReprE7KqrIkTJ+rZZ59tdXzFihUqKCiQJG3btk033nijKioqdNhhh2nChAmaPXu2unT534ZwRUWFbr31Vn300UfKzs7WnXfe6ffSBQAAAMSmkPe8AgAAAMESsssGAAAAgGAjvAIAACBqEF4BAAAQNQivAAAAiBqE10548MEHNXr0aKWkpPic4LV9+3aNGzdOKSkp6tu3r2677TYdOnTI45yKigqNHDlSycnJOvLII7Vw4cLQLz6MKioqZLPZvH6tW7dOklRTU+P1/jVr1li8+tCz2+2tnvfs2bM9ztm4caNOO+00devWTTk5OXr44YctWm141NTU6JprrlFubq66d++uwYMH6+6771ZjY6PHOfH6nnnyySdlt9vVrVs35eXltRr4EutmzZqlH/3oR+rRo4f69u2r888/X5s3b/Y4p6CgoNV744YbbrBoxeFzzz33tHrezadeHjhwQJMnT1bv3r2VmpqqCy+8sNUwoFjk7c9Zm82myZMnS4qv98tbb72lc889V/3795fNZtPLL7/scb9hGLrrrrvUr18/de/eXWPGjNEnn3zicc5XX32lyy67TGlpaerZs6euueYadxVqOBBeO6GxsVEXX3yxbrzxRq/3O51OjRs3To2NjXr33Xf17LPPauHChbrrrrvc51RXV2vcuHEqLCxUZWWlysrKdO2112rp0qXhehohN3r0aO3cudPj69prr1Vubq5OOukkj3OXLVvmcd6oUaMsWnV43XfffR7P+5ZbbnHfV19fr7Fjx2rgwIFav3695syZo3vuuUd//OMfLVxxaH388cdqamrSH/7wB3344Yd6/PHHNX/+fP3qV79qdW68vWeef/55TZ06VXfffbf+85//aMSIESoqKtKePXusXlrYrFy5UpMnT9aaNWtUXl6ugwcPauzYsdq/f7/HeZMmTfJ4b8T6X/pcjj32WI/n/c4777jvu/XWW/XPf/5TL774olauXKnPP/9cJSUlFq42PNatW+fxmpSXl0uSLr74Yvc58fJ+2b9/v0aMGKEnn3zS6/0PP/ywfvvb32r+/Plau3atDjvsMBUVFenAgQPucy677DJ9+OGHKi8v17/+9S+99dZbuu6668L1FCQDnbZgwQIjPT291fHXX3/dSEhIMHbt2uU+9tRTTxlpaWlGQ0ODYRiG8ctf/tI49thjPX7u0ksvNYqKikK6Zis1NjYaGRkZxn333ec+Vl1dbUgyNmzYYN3CLDJw4EDj8ccf93n/73//e+Pwww93v2cMwzBmzJhhDBkyJAyrixwPP/ywkZub674dr++Zk08+2Zg8ebL7ttPpNPr372/MmjXLwlVZa8+ePYYkY+XKle5jZ5xxhjFlyhTrFmWRu+++2xgxYoTX+/bt22d07drVePHFF93HqqqqDEnG6tWrw7TCyDBlyhRj8ODBRlNTk2EY8ft+kWS89NJL7ttNTU1GVlaWMWfOHPexffv2GcnJycbixYsNwzCMjz76yJBkrFu3zn3OG2+8YdhsNqO2tjYs62bnNYRWr16t4cOHKzMz032sqKhI9fX1+vDDD93njBkzxuPnioqKtHr16rCuNZxeffVV7d27V1dddVWr+8477zz17dtXp556ql599VULVmeN2bNnq3fv3jrxxBM1Z84cj0tLVq9erdNPP11JSUnuY0VFRdq8ebO+/vprK5Zribq6OvXq1avV8Xh6zzQ2Nmr9+vUef2YkJCRozJgxMf1nhj91dXWS1Or98dxzz6lPnz467rjjNHPmTH333XdWLC/sPvnkE/Xv31+DBg3SZZddpu3bt0uS1q9fr4MHD3q8f4YOHaoBAwbE1funsbFRf/3rX3X11VfLZrO5j8fr+6W56upq7dq1y+M9kp6erry8PPd7ZPXq1erZs6fHv5yOGTNGCQkJWrt2bVjW2cX/KeioXbt2eQRXSe7bu3btavOc+vp6ff/99+revXt4FhtGTz/9tIqKipSdne0+lpqaqkcffVSnnHKKEhIS9I9//EPnn3++Xn75ZZ133nkWrjb0fvGLX2jkyJHq1auX3n33Xc2cOVM7d+7UY489Jsl8j+Tm5nr8TPP30eGHHx72NYfbli1b9MQTT+iRRx5xH4vH98yXX34pp9Pp9c+Mjz/+2KJVWaupqUllZWU65ZRTdNxxx7mPl5aWauDAgerfv782btyoGTNmaPPmzXI4HBauNvTy8vK0cOFCDRkyRDt37tS9996r0047TZs2bdKuXbuUlJTU6jMamZmZ7v9Pigcvv/yy9u3b5zGtM17fLy253gfe/oxpnlv69u3rcX+XLl3Uq1evsL2PCK8t3H777XrooYfaPKeqqsrjAvh41ZHX6rPPPtPSpUv1wgsveJzXp08fTZ061X37Rz/6kT7//HPNmTMnKoNIe16b5s/7+OOPV1JSkq6//nrNmjUr4uZJd1ZH3jO1tbU666yzdPHFF2vSpEnu47H2nkHHTJ48WZs2bfK4rlOSx/V3w4cPV79+/XTmmWdq69atGjx4cLiXGTZnn322+9fHH3+88vLyNHDgQL3wwgsxuRnSEU8//bTOPvts9e/f330sXt8v0Yrw2sK0adM8/jbmzaBBgwJ6rKysrFafAnZ9qjMrK8v9veUnPXfv3q20tLSI/4OmI6/VggUL1Lt374DCRV5envui+mjTmfdRXl6eDh06pJqaGg0ZMsTne0T63/soWrT3dfn8889VWFio0aNHB/QBtWh+zwSiT58+SkxM9Pp+iLb3QjDcfPPN7g+LNP+XHG/y8vIkmbv48RRGevbsqaOPPlpbtmzRT3/6UzU2Nmrfvn0eu6/x9P7Ztm2bli1b5ndHNV7fL673we7du9WvXz/38d27d+uEE05wn9PyA6KHDh3SV199Fbb3EeG1hYyMDGVkZATlsfLz8/Xggw9qz5497i328vJypaWl6ZhjjnGf8/rrr3v8XHl5ufLz84OyhlBq72tlGIYWLFigK6+8Ul27dvV7fmVlpcd/PNGkM++jyspKJSQkuN8z+fn5+vWvf62DBw+6X7fy8nINGTIk6i4ZaM/rUltbq8LCQo0aNUoLFixQQoL/S/Sj+T0TiKSkJI0aNUrLly/X+eefL8n8Z/Ply5fr5ptvtnZxYWQYhm655Ra99NJLqqioaHVZjTeVlZWSFNPvD2++/fZbbd26VVdccYVGjRqlrl27avny5brwwgslSZs3b9b27duj4v9zgmHBggXq27evxo0b1+Z58fp+yc3NVVZWlpYvX+4Oq/X19Vq7dq27WSk/P1/79u3T+vXr3e0ub775ppqamtyhP+TC8rGwGLVt2zZjw4YNxr333mukpqYaGzZsMDZs2GB88803hmEYxqFDh4zjjjvOGDt2rFFZWWksWbLEyMjIMGbOnOl+jE8//dRISUkxbrvtNqOqqsp48sknjcTERGPJkiVWPa2QWbZsmSHJqKqqanXfwoULjUWLFhlVVVVGVVWV8eCDDxoJCQnGM888Y8FKw+fdd981Hn/8caOystLYunWr8de//tXIyMgwrrzySvc5+/btMzIzM40rrrjC2LRpk/G3v/3NSElJMf7whz9YuPLQ+uyzz4wjjzzSOPPMM43PPvvM2Llzp/vLJV7fM3/729+M5ORkY+HChcZHH31kXHfddUbPnj09Wk1i3Y033mikp6cbFRUVHu+N7777zjAMw9iyZYtx3333Ge+//75RXV1tvPLKK8agQYOM008/3eKVh960adOMiooKo7q62li1apUxZswYo0+fPsaePXsMwzCMG264wRgwYIDx5ptvGu+//76Rn59v5OfnW7zq8HA6ncaAAQOMGTNmeByPt/fLN998484rkozHHnvM2LBhg7Ft2zbDMAxj9uzZRs+ePY1XXnnF2Lhxo1FcXGzk5uYa33//vfsxzjrrLOPEE0801q5da7zzzjvGUUcdZYwfPz5sz4Hw2gkTJkwwJLX6WrFihfucmpoa4+yzzza6d+9u9OnTx5g2bZpx8OBBj8dZsWKFccIJJxhJSUnGoEGDjAULFoT3iYTJ+PHjjdGjR3u9b+HChcawYcOMlJQUIy0tzTj55JM96lxi1fr16428vDwjPT3d6NatmzFs2DDjN7/5jXHgwAGP8z744APj1FNPNZKTk40jjjjCmD17tkUrDo8FCxZ4/W+r+d+34/U9YxiG8cQTTxgDBgwwkpKSjJNPPtlYs2aN1UsKK1/vDdefndu3bzdOP/10o1evXkZycrJx5JFHGrfddptRV1dn7cLD4NJLLzX69etnJCUlGUcccYRx6aWXGlu2bHHf//333xs33XSTcfjhhxspKSnGBRdc4PGXwli2dOlSQ5KxefNmj+Px9n5ZsWKF1/9+JkyYYBiGWZd15513GpmZmUZycrJx5plntnrN9u7da4wfP95ITU010tLSjKuuusq9cRcONsMwjPDs8QIAAACdQ88rAAAAogbhFQAAAFGD8AoAAICoQXgFAABA1CC8AgAAIGoQXgEAABA1CK8AAACIGoRXAAAARA3CKwAAAKIG4RUAAABRg/AKAACAqPH/AV84zg5Sv3QbAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a NN\n",
        "\n",
        "# 1. Create a model\n",
        "model = tf.keras.Sequential([\n",
        "\n",
        "    # Input layer\n",
        "    tf.keras.layers.Input(shape=(1,)),\n",
        "\n",
        "    # Output layer\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "               optimizer=tf.keras.optimizers.SGD(),\n",
        "               metrics=['mae'])"
      ],
      "metadata": {
        "id": "PEettYVOsiDd"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Before fitting, let's visualize the model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xI311f0t8en",
        "outputId": "7018ea74-49a7-4aa3-e550-516ed87ed2aa"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_36 (Dense)            (None, 1)                 2         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2 (8.00 Byte)\n",
            "Trainable params: 2 (8.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Total params – the total number of parameters in the model (i.e., the total number of *patterns* our model is going to try to learn within the relationship between X and y).\n",
        "\n",
        "* Trainable params  – these are the parameters (patterns) the model can update as it trains.\n",
        "\n",
        "* Non-trainable params – these parameters aren't updated during the training (this is typical when you bring in already learned patterns or parameters from other models during **transfer learning**)."
      ],
      "metadata": {
        "id": "EZsRdJzqv-2w"
      }
    }
  ]
}